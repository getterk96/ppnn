{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": "true",
        "pycharm": {}
      },
      "source": [
        "\u003ch1\u003eTable of Contents\u003cspan class\u003d\"tocSkip\"\u003e\u003c/span\u003e\u003c/h1\u003e\n",
        "\u003cdiv class\u003d\"toc\"\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Fully-connected-linear-network\" data-toc-modified-id\u003d\"Fully-connected-linear-network-1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1\u0026nbsp;\u0026nbsp;\u003c/span\u003eFully connected linear network\u003c/a\u003e\u003c/span\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Get-temperature-data\" data-toc-modified-id\u003d\"Get-temperature-data-1.1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1.1\u0026nbsp;\u0026nbsp;\u003c/span\u003eGet temperature data\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Build-fully-connected-model\" data-toc-modified-id\u003d\"Build-fully-connected-model-1.2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1.2\u0026nbsp;\u0026nbsp;\u003c/span\u003eBuild fully connected model\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Predict-for-one-day\" data-toc-modified-id\u003d\"Predict-for-one-day-1.3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1.3\u0026nbsp;\u0026nbsp;\u003c/span\u003ePredict for one day\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Post-processing-with-rolling-window-for-2016\" data-toc-modified-id\u003d\"Post-processing-with-rolling-window-for-2016-1.4\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1.4\u0026nbsp;\u0026nbsp;\u003c/span\u003ePost processing with rolling window for 2016\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Train-2015,-predict-2016\" data-toc-modified-id\u003d\"Train-2015,-predict-2016-1.5\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e1.5\u0026nbsp;\u0026nbsp;\u003c/span\u003eTrain 2015, predict 2016\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Neural-network-with-one-hidden-layer\" data-toc-modified-id\u003d\"Neural-network-with-one-hidden-layer-2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e2\u0026nbsp;\u0026nbsp;\u003c/span\u003eNeural network with one hidden layer\u003c/a\u003e\u003c/span\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Build-network\" data-toc-modified-id\u003d\"Build-network-2.1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e2.1\u0026nbsp;\u0026nbsp;\u003c/span\u003eBuild network\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Train-2015,-predict-2016\" data-toc-modified-id\u003d\"Train-2015,-predict-2016-2.2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e2.2\u0026nbsp;\u0026nbsp;\u003c/span\u003eTrain 2015, predict 2016\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Making-the-hidden-model-more-complex\" data-toc-modified-id\u003d\"Making-the-hidden-model-more-complex-2.3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e2.3\u0026nbsp;\u0026nbsp;\u003c/span\u003eMaking the hidden model more complex\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Add-station-embeddings\" data-toc-modified-id\u003d\"Add-station-embeddings-3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e3\u0026nbsp;\u0026nbsp;\u003c/span\u003eAdd station embeddings\u003c/a\u003e\u003c/span\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Build-linear-embedding-model\" data-toc-modified-id\u003d\"Build-linear-embedding-model-3.1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e3.1\u0026nbsp;\u0026nbsp;\u003c/span\u003eBuild linear embedding model\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Train-2015,-predict-2016\" data-toc-modified-id\u003d\"Train-2015,-predict-2016-3.2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e3.2\u0026nbsp;\u0026nbsp;\u003c/span\u003eTrain 2015, predict 2016\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Embedding-size-hyper-parameter-tuning\" data-toc-modified-id\u003d\"Embedding-size-hyper-parameter-tuning-3.3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e3.3\u0026nbsp;\u0026nbsp;\u003c/span\u003eEmbedding size hyper-parameter tuning\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Adding-auxiliary-variables\" data-toc-modified-id\u003d\"Adding-auxiliary-variables-4\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4\u0026nbsp;\u0026nbsp;\u003c/span\u003eAdding auxiliary variables\u003c/a\u003e\u003c/span\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Load-extended-dataset\" data-toc-modified-id\u003d\"Load-extended-dataset-4.1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.1\u0026nbsp;\u0026nbsp;\u003c/span\u003eLoad extended dataset\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Linear-model\" data-toc-modified-id\u003d\"Linear-model-4.2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.2\u0026nbsp;\u0026nbsp;\u003c/span\u003eLinear model\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Hidden-model\" data-toc-modified-id\u003d\"Hidden-model-4.3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.3\u0026nbsp;\u0026nbsp;\u003c/span\u003eHidden model\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Even-more-variables\" data-toc-modified-id\u003d\"Even-more-variables-4.4\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.4\u0026nbsp;\u0026nbsp;\u003c/span\u003eEven more variables\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Save-pickled-datasets\" data-toc-modified-id\u003d\"Save-pickled-datasets-4.5\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.5\u0026nbsp;\u0026nbsp;\u003c/span\u003eSave pickled datasets\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Train-model\" data-toc-modified-id\u003d\"Train-model-4.6\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e4.6\u0026nbsp;\u0026nbsp;\u003c/span\u003eTrain model\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Additional-variables-with-the-embedding-model\" data-toc-modified-id\u003d\"Additional-variables-with-the-embedding-model-5\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e5\u0026nbsp;\u0026nbsp;\u003c/span\u003eAdditional variables with the embedding model\u003c/a\u003e\u003c/span\u003e\u003cul class\u003d\"toc-item\"\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Linear-model-with-embeddings\" data-toc-modified-id\u003d\"Linear-model-with-embeddings-5.1\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e5.1\u0026nbsp;\u0026nbsp;\u003c/span\u003eLinear model with embeddings\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Hidden-model-with-embeddings\" data-toc-modified-id\u003d\"Hidden-model-with-embeddings-5.2\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e5.2\u0026nbsp;\u0026nbsp;\u003c/span\u003eHidden model with embeddings\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#A-longer-training-period\" data-toc-modified-id\u003d\"A-longer-training-period-5.3\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e5.3\u0026nbsp;\u0026nbsp;\u003c/span\u003eA longer training period\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#A-longer-training-period-with-more-data\" data-toc-modified-id\u003d\"A-longer-training-period-with-more-data-5.4\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e5.4\u0026nbsp;\u0026nbsp;\u003c/span\u003eA longer training period with more data\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/li\u003e\u003cli\u003e\u003cspan\u003e\u003ca href\u003d\"#Data-augmentation\" data-toc-modified-id\u003d\"Data-augmentation-6\"\u003e\u003cspan class\u003d\"toc-item-num\"\u003e6\u0026nbsp;\u0026nbsp;\u003c/span\u003eData augmentation\u003c/a\u003e\u003c/span\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Fully connected and neural networks\n",
        "\n",
        "Now that we have established that we can get equivalent EMOS results using a network architecture with SGD, we can now extend this approach to fully connected networks. \n",
        "\n",
        "Here we will try several approaches:\n",
        "- Simple linear fully connected networks\n",
        "- Neural networks with hidden layers\n",
        "- Adding station embeddings\n",
        "- Adding additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys\n",
        "sys.path.append(\u0027../\u0027)   # This is where all the python files are!\n",
        "from importlib import reload\n",
        "from nn_src.emos_network_theano import EMOS_Network\n",
        "from nn_src.losses import crps_cost_function\n",
        "from nn_src.utils import *\n",
        "from nn_src.keras_models import *\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Basic setup\n",
        "DATA_DIR \u003d \u0027/data/gaojinghan/EC_ensemble/manipulated/\u0027  # Mac\n",
        "# DATA_DIR \u003d \u0027/project/meteo/w2w/C7/ppnn_data/\u0027   # LMU\n",
        "results_dir \u003d \u0027./\u0027\n",
        "window_size \u003d 25   # Days in rolling window\n",
        "fclt \u003d 0   # Forecast lead time in hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Fully connected linear network\n",
        "\n",
        "As a first step, we can build a linear model which also connects the means and standard deviations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### Get temperature data\n",
        "\n",
        "This follows the steps in the EMOS Network data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 25 days\n",
            "test set contains 1 days\n"
          ]
        }
      ],
      "source": "date_str \u003d \u00272019-04-21-00\u0027\ntrain_set, test_set \u003d get_train_test_sets(DATA_DIR, predict_date\u003ddate_str,\n                                          fclt\u003dfclt, window_size\u003dwindow_size,\n                                          full_ensemble_t\u003dTrue)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### Build fully connected model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "fc_model \u003d build_fc_model(51, 2, compile\u003dTrue)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_1 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 6         \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "fc_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "Now we have 6 parameters instead of 4 with the standard EMOS Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### Predict for one day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# Define some parameters\n",
        "early_stopping_delta \u003d 1e-4   # How much the CRPS must improve before stopping\n",
        "steps_max \u003d 1000   # How many steps to fit at max\n",
        "batch_size \u003d train_set.features.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model.fit(train_set.features, train_set.targets, epochs\u003dsteps_max, \n",
        "             batch_size\u003dbatch_size,\n",
        "             validation_data\u003d[test_set.features, test_set.targets], \n",
        "             verbose\u003d0,\n",
        "             callbacks\u003d[EarlyStopping(monitor\u003d\u0027loss\u0027, \n",
        "                                      min_delta\u003dearly_stopping_delta,\n",
        "                                      patience\u003d2)]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2.1292445659637451, 1.9690423011779785)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get train and test CRPS\n",
        "(fc_model.evaluate(train_set.features, train_set.targets, batch_size, verbose\u003d0), \n",
        " fc_model.evaluate(test_set.features, test_set.targets, batch_size, verbose\u003d0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "For this particular day we get a score that is slightly better than the standard EMOS network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### Post processing with rolling window for 2016\n",
        "\n",
        "As with the EMOS models let\u0027s do a rolling window global post-processing for 2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "date_str_start \u003d \u00272019-01-03-00\u0027\n",
        "date_str_stop \u003d \u00272019-04-21-00\u0027"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model \u003d build_fc_model(2, 2, compile\u003dTrue, optimizer\u003d\u0027sgd\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 123/123 [1:37:46\u003c00:00, 47.70s/it]\n"
          ]
        }
      ],
      "source": [
        "# Use the loop function in utils\n",
        "train_crps_list, valid_crps_list, results_df \u003d loop_over_days(\n",
        "    DATA_DIR,\n",
        "    fc_model,\n",
        "    date_str_start, date_str_stop, \n",
        "    window_size\u003dwindow_size,\n",
        "    fclt\u003dfclt,     \n",
        "    epochs_max\u003dsteps_max, \n",
        "    early_stopping_delta\u003dearly_stopping_delta, \n",
        "    lr\u003d0.1,   \n",
        "    verbose\u003d0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2.0113473233057779, 2.0649313205646451)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(train_crps_list), np.mean(valid_crps_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "So we get a slightly better training score and a slightly worse test score. This is a sign of overfitting. But the differences are small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "results_df.to_csv(results_dir + \u0027fc_network_rolling_window.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### Train 2015, predict 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 365 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "train_dates \u003d [\u00272015-01-01\u0027, \u00272016-01-01\u0027]\n",
        "test_dates \u003d  [\u00272016-01-01\u0027, \u00272017-01-01\u0027]\n",
        "train_set, test_set \u003d get_train_test_sets(DATA_DIR, train_dates, test_dates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180849, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model \u003d build_fc_model(2, 2, compile\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "\u003csvg height\u003d\"118pt\" viewBox\u003d\"0.00 0.00 136.36 118.00\" width\u003d\"136pt\" xmlns\u003d\"http://www.w3.org/2000/svg\" xmlns:xlink\u003d\"http://www.w3.org/1999/xlink\"\u003e\n",
              "\u003cg class\u003d\"graph\" id\u003d\"graph0\" transform\u003d\"scale(1 1) rotate(0) translate(4 114)\"\u003e\n",
              "\u003ctitle\u003eG\u003c/title\u003e\n",
              "\u003cpolygon fill\u003d\"white\" points\u003d\"-4,4 -4,-114 132.362,-114 132.362,4 -4,4\" stroke\u003d\"none\"/\u003e\n",
              "\u003c!-- 4693707520 --\u003e\n",
              "\u003cg class\u003d\"node\" id\u003d\"node1\"\u003e\u003ctitle\u003e4693707520\u003c/title\u003e\n",
              "\u003cpolygon fill\u003d\"none\" points\u003d\"0,-73.5 0,-109.5 128.362,-109.5 128.362,-73.5 0,-73.5\" stroke\u003d\"black\"/\u003e\n",
              "\u003ctext font-family\u003d\"Times,serif\" font-size\u003d\"14.00\" text-anchor\u003d\"middle\" x\u003d\"64.1812\" y\u003d\"-87.3\"\u003einput_1: InputLayer\u003c/text\u003e\n",
              "\u003c/g\u003e\n",
              "\u003c!-- 4788921008 --\u003e\n",
              "\u003cg class\u003d\"node\" id\u003d\"node2\"\u003e\u003ctitle\u003e4788921008\u003c/title\u003e\n",
              "\u003cpolygon fill\u003d\"none\" points\u003d\"12.0552,-0.5 12.0552,-36.5 116.307,-36.5 116.307,-0.5 12.0552,-0.5\" stroke\u003d\"black\"/\u003e\n",
              "\u003ctext font-family\u003d\"Times,serif\" font-size\u003d\"14.00\" text-anchor\u003d\"middle\" x\u003d\"64.1812\" y\u003d\"-14.3\"\u003edense_1: Dense\u003c/text\u003e\n",
              "\u003c/g\u003e\n",
              "\u003c!-- 4693707520\u0026#45;\u0026gt;4788921008 --\u003e\n",
              "\u003cg class\u003d\"edge\" id\u003d\"edge1\"\u003e\u003ctitle\u003e4693707520-\u0026gt;4788921008\u003c/title\u003e\n",
              "\u003cpath d\u003d\"M64.1812,-73.3129C64.1812,-65.2895 64.1812,-55.5475 64.1812,-46.5691\" fill\u003d\"none\" stroke\u003d\"black\"/\u003e\n",
              "\u003cpolygon fill\u003d\"black\" points\u003d\"67.6813,-46.5288 64.1812,-36.5288 60.6813,-46.5289 67.6813,-46.5288\" stroke\u003d\"black\"/\u003e\n",
              "\u003c/g\u003e\n",
              "\u003c/g\u003e\n",
              "\u003c/svg\u003e"
            ],
            "text/plain": [
              "\u003cIPython.core.display.SVG object\u003e"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(fc_model).create(prog\u003d\u0027dot\u0027, format\u003d\u0027svg\u0027))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model.compile(keras.optimizers.Adam(0.001), loss\u003dcrps_cost_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 2.9808 - val_loss: 1.9917\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.3618 - val_loss: 1.0581\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0732 - val_loss: 1.0128\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0693 - val_loss: 1.0120\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0692 - val_loss: 1.0125\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0692 - val_loss: 1.0135\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0693 - val_loss: 1.0121\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0692 - val_loss: 1.0124\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0693 - val_loss: 1.0123\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0693 - val_loss: 1.0133\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x136249cf8\u003e"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note: I am running this cell several times (40)\n",
        "fc_model.fit(train_set.features, train_set.targets, epochs\u003d10, batch_size\u003d1024,\n",
        "             validation_data\u003d[test_set.features, test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "182218/182218 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s     \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0133071342532698"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fc_model.evaluate(test_set.features, test_set.targets, 4096)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "Very similar to the standard EMOS Network. This indicates that there is not much additional information in the two extra connections we added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d fc_model.predict(test_set.features)\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027fc_network_train_2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "## Neural network with one hidden layer\n",
        "\n",
        "Now we will build the first neural network with a hidden layer and a non-linear activation function. We will restrict ourselves to testing the 2015 training, 2016 prediction case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Build network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "hidden_model \u003d build_hidden_model(2, 2, hidden_nodes\u003d10, compile\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_7 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 22        \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 52\n",
            "Trainable params: 52\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "hidden_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Train 2015, predict 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "hidden_model.compile(keras.optimizers.Adam(0.0001), loss\u003dcrps_cost_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 4.1429 - val_loss: 1.4222\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.1146 - val_loss: 1.0142\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0724 - val_loss: 1.0159\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0716 - val_loss: 1.0158\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0718 - val_loss: 1.0135\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0715 - val_loss: 1.0147\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0714 - val_loss: 1.0136\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0710 - val_loss: 1.0144\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0710 - val_loss: 1.0139\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0712 - val_loss: 1.0161\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x1157c4470\u003e"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can use the same data from above!\n",
        "# Note I am running this cell several times\n",
        "hidden_model.fit(train_set.features, train_set.targets, epochs\u003d10, batch_size\u003d1024,\n",
        "                 validation_data\u003d[test_set.features, test_set.targets])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "Again, the results are pretty similar. This indicates that for the given data, the added nonlinearity is not important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d hidden_model.predict(test_set.features)\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027hidden_nn_train_2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Making the hidden model more complex\n",
        "\n",
        "Let\u0027s see what happens if we make the model more complex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "hidden_model \u003d build_hidden_model(2, 2, hidden_nodes\u003d[100, 100, 100], compile\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_9 (InputLayer)         (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 202       \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 20,702\n",
            "Trainable params: 20,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "hidden_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "hidden_model.compile(keras.optimizers.Adam(0.0001), loss\u003dcrps_cost_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0217\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0224\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0571 - val_loss: 1.0223\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0221\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0223\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0570 - val_loss: 1.0223\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0569 - val_loss: 1.0219\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.0569 - val_loss: 1.0221\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x118c75860\u003e"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_model.fit(train_set.features, train_set.targets, epochs\u003d10, batch_size\u003d4096,\n",
        "                 validation_data\u003d[test_set.features, test_set.targets])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "So we can see that even for a model with 20,000 parameters then training score only goes down a few percent. For a simple bias and spread correction, a linear model seems fully sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "## Add station embeddings\n",
        "\n",
        "Next we will add a station embedding. Here we are giving every station additional parameters which the model can learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Build linear embedding model\n",
        "\n",
        "Let\u0027s build a linear embedding model. I tried out hidden layers, but they seem to make the validation score worse!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "536"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_size \u003d 3\n",
        "max_id \u003d int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))\n",
        "max_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model \u003d build_emb_model(2, 2, [], emb_size, max_id, compile\u003dTrue,\n",
        "                            lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_21 (InputLayer)            (None, 1)             0                                            \n",
            "____________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)          (None, 1, 3)          1611        input_21[0][0]                   \n",
            "____________________________________________________________________________________________________\n",
            "input_20 (InputLayer)            (None, 2)             0                                            \n",
            "____________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)              (None, 3)             0           embedding_6[0][0]                \n",
            "____________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)      (None, 5)             0           input_20[0][0]                   \n",
            "                                                                   flatten_6[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "dense_26 (Dense)                 (None, 2)             12          concatenate_6[0][0]              \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 1,623\n",
            "Trainable params: 1,623\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "emb_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Train 2015, predict 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9690 - val_loss: 0.9132\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9691 - val_loss: 0.9129\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9690 - val_loss: 0.9129\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9690 - val_loss: 0.9136\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9691 - val_loss: 0.9132\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9689 - val_loss: 0.9139\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9689 - val_loss: 0.9131\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9690 - val_loss: 0.9138\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9689 - val_loss: 0.9128\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9690 - val_loss: 0.9134\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x11b9b5c50\u003e"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ran this for 40 epochs\n",
        "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
        "              epochs\u003d10, batch_size\u003d1024, \n",
        "              validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d emb_model.predict([test_set.features, test_set.cont_ids])\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027embedding_fc_train_2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Embedding size hyper-parameter tuning\n",
        "\n",
        "Since embeddings appear to work very well, we will test the impact of the embedding size before building more complex models. Of course, a larger embedding size might be useful when adding more variables, but this should give us some feeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def build_and_run_emb_model(emb_size):\n",
        "    emb_model \u003d build_emb_model(2, 2, [], emb_size, max_id, compile\u003dTrue)\n",
        "    emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
        "                  epochs\u003d40,batch_size\u003d1024, verbose\u003d0,\n",
        "                  validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])\n",
        "    print(emb_model.evaluate([train_set.features, train_set.cont_ids], train_set.targets, verbose\u003d0),\n",
        "          emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, verbose\u003d0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0.975157575805 0.918841918992\n",
            "2\n",
            "0.96694133538 0.913661904937\n",
            "3\n",
            "0.967165116694 0.912928815584\n",
            "5\n",
            "0.967104299998 0.914134442874\n",
            "10\n",
            "0.968233569106 0.915652121524\n",
            "20\n",
            "0.969342381379 0.912989628939\n"
          ]
        }
      ],
      "source": [
        "for emb_size in [1, 2, 3, 5, 10, 20]:\n",
        "    print(emb_size)\n",
        "    build_and_run_emb_model(emb_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "Note that there is some variability. In our first experiment above with an embedding size of 5 we got a better score than here. For this very simple network an embedding size of three seems sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "pycharm": {}
      },
      "source": [
        "## Adding auxiliary variables\n",
        "\n",
        "Now we can try adding additional variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Load extended dataset\n",
        "\n",
        "Using the function defined in utils."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# The prepare_data function takes an ordered dict as an input\n",
        "aux_dict \u003d OrderedDict()\n",
        "aux_dict[\u0027data_aux_geo_interpolated.nc\u0027] \u003d [\u0027orog\u0027, \n",
        "                                            \u0027station_alt\u0027, \n",
        "                                            \u0027station_lat\u0027, \n",
        "                                            \u0027station_lon\u0027]\n",
        "aux_dict[\u0027data_aux_pl500_interpolated_00UTC.nc\u0027] \u003d [\u0027u_pl500_fc\u0027,\n",
        "                                                    \u0027v_pl500_fc\u0027,\n",
        "                                                    \u0027gh_pl500_fc\u0027]\n",
        "aux_dict[\u0027data_aux_pl850_interpolated_00UTC.nc\u0027] \u003d [\u0027u_pl850_fc\u0027,\n",
        "                                                    \u0027v_pl850_fc\u0027,\n",
        "                                                    \u0027q_pl850_fc\u0027]\n",
        "aux_dict[\u0027data_aux_surface_interpolated_00UTC.nc\u0027] \u003d [\u0027cape_fc\u0027,\n",
        "                                                      \u0027sp_fc\u0027,\n",
        "                                                      \u0027tcc_fc\u0027]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 365 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "train_dates \u003d [\u00272015-01-01\u0027, \u00272016-01-01\u0027]\n",
        "test_dates \u003d  [\u00272016-01-01\u0027, \u00272017-01-01\u0027]\n",
        "train_set, test_set \u003d get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
        "                                         aux_dict\u003daux_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180849, 24)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model \u003d build_fc_model(train_set.features.shape[1], 2, compile\u003dTrue, \n",
        "                          lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9701 - val_loss: 0.9389\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9395\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9405\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9700 - val_loss: 0.9385\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9702 - val_loss: 0.9380\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9385\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9384\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9400\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9698 - val_loss: 0.9388\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9699 - val_loss: 0.9382\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x11c21d5c0\u003e"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that I am running this cell multiple times\n",
        "fc_model.fit(train_set.features, train_set.targets, epochs\u003d10, batch_size\u003d1024,\n",
        "             validation_data\u003d[test_set.features, test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d fc_model.predict([test_set.features, test_set.cont_ids])\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027embedding_fc_train_2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Hidden model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "hidden_model \u003d build_hidden_model(train_set.features.shape[1], 2, \n",
        "                                  hidden_nodes\u003d[50], compile\u003dTrue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_49 (InputLayer)        (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 50)                1250      \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 2)                 102       \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 1,352\n",
            "Trainable params: 1,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "hidden_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9388 - val_loss: 0.9402\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9348 - val_loss: 0.9332\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9346 - val_loss: 0.9367\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9295 - val_loss: 0.9418\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9292 - val_loss: 0.9356\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9275 - val_loss: 0.9392\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9253 - val_loss: 0.9365\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9251 - val_loss: 0.9378\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9239 - val_loss: 0.9441\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9232 - val_loss: 0.9310\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x1264243c8\u003e"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that I am running this cell multiple times\n",
        "hidden_model.fit(train_set.features, train_set.targets, epochs\u003d10, batch_size\u003d1024,\n",
        "             validation_data\u003d[test_set.features, test_set.targets])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "So we see a definite improvement using auxiliary variables. Again, the hidden layer does not seem to improve things a lot compared to the simple linear model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Even more variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "more_aux_dict \u003d aux_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "more_aux_dict[\u0027data_aux_surface_more_interpolated_part1_00UTC.nc\u0027]  \u003d [\n",
        "    \u0027sshf_fc\u0027, \u0027slhf_fc\u0027, \u0027u10_fc\u0027,\u0027v10_fc\u0027\n",
        "]\n",
        "more_aux_dict[\u0027data_aux_surface_more_interpolated_part2_00UTC.nc\u0027]  \u003d [\n",
        "    \u0027ssr_fc\u0027, \u0027str_fc\u0027, \u0027d2m_fc\u0027,\u0027sm_fc\u0027\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "train_dates \u003d [\u00272015-01-01\u0027, \u00272016-01-01\u0027]\n",
        "test_dates \u003d  [\u00272016-01-01\u0027, \u00272017-01-01\u0027]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 365 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "more_train_set, more_test_set \u003d get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
        "                                         aux_dict\u003dmore_aux_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180849, 40)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "more_train_set.features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Save pickled datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[30m\u001b[43mauxiliary\u001b[m\u001b[m/                  \u001b[31mdata_interpolated_00UTC.nc\u001b[m\u001b[m*\r\n",
            "\u001b[31mdata_interpolated.nc\u001b[m\u001b[m*\r\n"
          ]
        }
      ],
      "source": [
        "%ls $DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "with open(DATA_DIR + \u0027aux_15_16.pkl\u0027, \u0027wb\u0027) as f:\n",
        "    pickle.dump((more_train_set, more_test_set), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def save_pickle(fn, train_dates\u003d[\u00272015-01-01\u0027, \u00272016-01-01\u0027], add_current_error\u003dFalse,\n",
        "                current_error_len\u003d1):\n",
        "    sets \u003d get_train_test_sets(\n",
        "        DATA_DIR, train_dates, test_dates, aux_dict\u003dmore_aux_dict,\n",
        "        add_current_error\u003dadd_current_error, current_error_len\u003dcurrent_error_len\n",
        "    )\n",
        "    with open(DATA_DIR + fn, \u0027wb\u0027) as f:\n",
        "        pickle.dump(sets, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 365 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "save_pickle(\u0027aux_15_16_current30.pkl\u0027, [\u00272015-01-01\u0027, \u00272016-01-01\u0027], \n",
        "            add_current_error\u003dTrue, current_error_len\u003d30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 730 days\n",
            "test set contains 366 days\n",
            "train set contains 1095 days\n",
            "test set contains 366 days\n",
            "train set contains 2191 days\n",
            "test set contains 366 days\n",
            "train set contains 2922 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "save_pickle(\u0027aux_14-15_16.pkl\u0027, [\u00272014-01-01\u0027, \u00272016-01-01\u0027])\n",
        "save_pickle(\u0027aux_13-15_16.pkl\u0027, [\u00272013-01-01\u0027, \u00272016-01-01\u0027])\n",
        "save_pickle(\u0027aux_10-15_16.pkl\u0027, [\u00272010-01-01\u0027, \u00272016-01-01\u0027])\n",
        "save_pickle(\u0027aux_08-15_16.pkl\u0027, [\u00272008-01-01\u0027, \u00272016-01-01\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 1461 days\n",
            "test set contains 366 days\n",
            "train set contains 1826 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "save_pickle(\u0027aux_12-15_16.pkl\u0027, [\u00272012-01-01\u0027, \u00272016-01-01\u0027])\n",
        "save_pickle(\u0027aux_11-15_16.pkl\u0027, [\u00272011-01-01\u0027, \u00272016-01-01\u0027])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "fc_model \u003d build_fc_model(more_train_set.features.shape[1], 2, compile\u003dTrue, \n",
        "                          lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9540 - val_loss: 0.9163\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9542 - val_loss: 0.9231\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9546 - val_loss: 0.9159\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9546 - val_loss: 0.9242\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9544 - val_loss: 0.9152\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9549 - val_loss: 0.9251\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9545 - val_loss: 0.9161\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9542 - val_loss: 0.9193\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9545 - val_loss: 0.9177\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9539 - val_loss: 0.9221\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f2aed4cd4e0\u003e"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that I am running this cell multiple times\n",
        "fc_model.fit(more_train_set.features, more_train_set.targets, epochs\u003d10, batch_size\u003d1024,\n",
        "             validation_data\u003d[more_test_set.features, more_test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "hidden": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "pycharm": {}
      },
      "source": [
        "Adding these extra variables gets us another percent or so"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Additional variables with the embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Linear model with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model \u003d build_emb_model(train_set.features.shape[1], 2, [], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_2 (InputLayer)             (None, 1)             0                                            \n",
            "____________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)          (None, 1, 3)          1611        input_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "input_1 (InputLayer)             (None, 24)            0                                            \n",
            "____________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)              (None, 3)             0           embedding_1[0][0]                \n",
            "____________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)      (None, 27)            0           input_1[0][0]                    \n",
            "                                                                   flatten_1[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "dense_1 (Dense)                  (None, 2)             56          concatenate_1[0][0]              \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 1,667\n",
            "Trainable params: 1,667\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "emb_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model.optimizer.lr\u003d0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9234 - val_loss: 0.9007\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9232 - val_loss: 0.8995\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9233 - val_loss: 0.8985\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9231 - val_loss: 0.9004\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9231 - val_loss: 0.8981\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9230 - val_loss: 0.8987\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9232 - val_loss: 0.8977\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9231 - val_loss: 0.8979\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9229 - val_loss: 0.8969\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9231 - val_loss: 0.9000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f96c40f5dd8\u003e"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again I am running this multiple times\n",
        "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs\u003d10, \n",
        "              batch_size\u003d1024, \n",
        "              validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Hidden model with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name \u0027train_set\u0027 is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-16-ff5627243658\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m emb_model \u003d build_emb_model(train_set.features.shape[1], 2, [50], 3, max_id, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             compile\u003dTrue, lr\u003d0.01)\n",
            "\u001b[0;31mNameError\u001b[0m: name \u0027train_set\u0027 is not defined"
          ]
        }
      ],
      "source": [
        "emb_model \u003d build_emb_model(train_set.features.shape[1], 2, [50], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8592 - val_loss: 0.8559\n",
            "Epoch 2/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8536 - val_loss: 0.8559\n",
            "Epoch 3/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8524 - val_loss: 0.8590\n",
            "Epoch 4/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8498 - val_loss: 0.8570\n",
            "Epoch 5/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8500 - val_loss: 0.8580\n",
            "Epoch 6/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8478 - val_loss: 0.8885\n",
            "Epoch 7/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8465 - val_loss: 0.8572\n",
            "Epoch 8/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8449 - val_loss: 0.8564\n",
            "Epoch 9/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8438 - val_loss: 0.8583\n",
            "Epoch 10/10\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8440 - val_loss: 0.8613\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f95e113fcc0\u003e"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again I am running this multiple times\n",
        "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs\u003d10, \n",
        "              batch_size\u003d4096, \n",
        "              validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "This is our best score so far. Here the non-linearity seems to make a difference compared to the simple linear model. But we do get some overfitting. Let\u0027s try out some techniques. Fewer or more hidden nodes does not seem to change all that much.\n",
        "\n",
        "No we need to be very careful here. I am currently stopping when the validation score does not decrease further. THIS IS CHEATING!\n",
        "\n",
        "Let\u0027s try doing the train valid split just with the training set, and see if we can get a good early stopping point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "max_id \u003d int(np.max([train_set.cont_ids.max(), test_set.cont_ids.max()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model \u003d build_emb_model(train_set.features.shape[1], 2, [50], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 144679 samples, validate on 36170 samples\n",
            "Epoch 1/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 4.6977 - val_loss: 2.3896\n",
            "Epoch 2/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 2.5777 - val_loss: 1.8083\n",
            "Epoch 3/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.3762 - val_loss: 1.1476\n",
            "Epoch 4/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 1.0260 - val_loss: 1.0796\n",
            "Epoch 5/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9704 - val_loss: 1.0552\n",
            "Epoch 6/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9508 - val_loss: 1.0323\n",
            "Epoch 7/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9369 - val_loss: 1.0165\n",
            "Epoch 8/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9260 - val_loss: 1.0029\n",
            "Epoch 9/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9199 - val_loss: 0.9962\n",
            "Epoch 10/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9133 - val_loss: 0.9905\n",
            "Epoch 11/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9092 - val_loss: 0.9868\n",
            "Epoch 12/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9064 - val_loss: 0.9832\n",
            "Epoch 13/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9035 - val_loss: 0.9789\n",
            "Epoch 14/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.9005 - val_loss: 0.9757\n",
            "Epoch 15/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8962 - val_loss: 0.9704\n",
            "Epoch 16/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8904 - val_loss: 0.9731\n",
            "Epoch 17/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8828 - val_loss: 0.9568\n",
            "Epoch 18/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8703 - val_loss: 0.9546\n",
            "Epoch 19/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8659 - val_loss: 0.9551\n",
            "Epoch 20/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8602 - val_loss: 0.9513\n",
            "Epoch 21/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8587 - val_loss: 0.9509\n",
            "Epoch 22/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8563 - val_loss: 0.9473\n",
            "Epoch 23/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8528 - val_loss: 0.9582\n",
            "Epoch 24/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8512 - val_loss: 0.9488\n",
            "Epoch 25/50\n",
            "144679/144679 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 0s - loss: 0.8479 - val_loss: 0.9575\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f2a3c190208\u003e"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again I am running this multiple times\n",
        "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, epochs\u003d50, \n",
        "              batch_size\u003d4096, validation_split\u003d0.2,\n",
        "              callbacks\u003d[EarlyStopping(monitor\u003d\u0027val_loss\u0027, \n",
        "                                       min_delta\u003d0,\n",
        "                                       patience\u003d2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170000/182218 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8661767004406562"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, batch_size\u003d10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d emb_model.predict([test_set.features, test_set.cont_ids])\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027embedding_nn_aux_train_2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### A longer training period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 2922 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "long_train_dates \u003d [\u00272008-01-01\u0027, \u00272016-01-01\u0027]\n",
        "test_dates \u003d  [\u00272016-01-01\u0027, \u00272017-01-01\u0027]\n",
        "long_train_set, test_set \u003d get_train_test_sets(DATA_DIR, long_train_dates, test_dates,\n",
        "                                               aux_dict\u003daux_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name \u0027long_train_set\u0027 is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-15-900b4033026f\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m emb_model \u003d build_emb_model(long_train_set.features.shape[1], 2, [50], 3, max_id, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             compile\u003dTrue, lr\u003d0.01)\n",
            "\u001b[0;31mNameError\u001b[0m: name \u0027long_train_set\u0027 is not defined"
          ]
        }
      ],
      "source": [
        "emb_model \u003d build_emb_model(long_train_set.features.shape[1], 2, [50], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 1165581 samples, validate on 291396 samples\n",
            "Epoch 1/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.4502 - val_loss: 0.9145\n",
            "Epoch 2/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9202 - val_loss: 0.8564\n",
            "Epoch 3/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8807 - val_loss: 0.8377\n",
            "Epoch 4/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8701 - val_loss: 0.8407\n",
            "Epoch 5/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8637 - val_loss: 0.8339\n",
            "Epoch 6/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8568 - val_loss: 0.8292\n",
            "Epoch 7/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8490 - val_loss: 0.8261\n",
            "Epoch 8/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8440 - val_loss: 0.8225\n",
            "Epoch 9/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8399 - val_loss: 0.8217\n",
            "Epoch 10/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8383 - val_loss: 0.8156\n",
            "Epoch 11/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8364 - val_loss: 0.8159\n",
            "Epoch 12/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8346 - val_loss: 0.8159\n",
            "Epoch 13/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8327 - val_loss: 0.8124\n",
            "Epoch 14/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8311 - val_loss: 0.8180\n",
            "Epoch 15/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8304 - val_loss: 0.8205\n",
            "Epoch 16/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8298 - val_loss: 0.8160\n",
            "Epoch 17/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8260 - val_loss: 0.8331\n",
            "Epoch 18/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8263 - val_loss: 0.8065\n",
            "Epoch 19/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8244 - val_loss: 0.8076\n",
            "Epoch 20/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8231 - val_loss: 0.8086\n",
            "Epoch 21/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8222 - val_loss: 0.8100\n",
            "Epoch 22/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8205 - val_loss: 0.8088\n",
            "Epoch 23/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8212 - val_loss: 0.8046\n",
            "Epoch 24/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8183 - val_loss: 0.8043\n",
            "Epoch 25/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8190 - val_loss: 0.8064\n",
            "Epoch 26/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8188 - val_loss: 0.8047\n",
            "Epoch 27/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8181 - val_loss: 0.8219\n",
            "Epoch 28/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8192 - val_loss: 0.8082\n",
            "Epoch 29/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8155 - val_loss: 0.8045\n",
            "Epoch 30/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8163 - val_loss: 0.8183\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f2aec0a6e80\u003e"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again I am running this multiple times\n",
        "emb_model.fit([long_train_set.features, long_train_set.cont_ids], long_train_set.targets, \n",
        "              epochs\u003d50, \n",
        "              batch_size\u003d4096, validation_split\u003d0.2,\n",
        "              callbacks\u003d[EarlyStopping(monitor\u003d\u0027val_loss\u0027, \n",
        "                                       min_delta\u003d0,\n",
        "                                       patience\u003d5)]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170000/182218 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7918927852063512"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model.evaluate([test_set.features, test_set.cont_ids], test_set.targets, batch_size\u003d10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d emb_model.predict([test_set.features, test_set.cont_ids])\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027embedding_nn_aux_train_2008-2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": [
        "### A longer training period with more data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 2922 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "long_more_train_set, more_test_set \u003d get_train_test_sets(DATA_DIR, long_train_dates, test_dates,\n",
        "                                                         aux_dict\u003dmore_aux_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model \u003d build_emb_model(long_more_train_set.features.shape[1], 2, [100], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 1165581 samples, validate on 291396 samples\n",
            "Epoch 1/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 1.4866 - val_loss: 0.8848\n",
            "Epoch 2/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8875 - val_loss: 0.8467\n",
            "Epoch 3/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8628 - val_loss: 0.8289\n",
            "Epoch 4/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8504 - val_loss: 0.8384\n",
            "Epoch 5/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8424 - val_loss: 0.8217\n",
            "Epoch 6/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8376 - val_loss: 0.8203\n",
            "Epoch 7/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8350 - val_loss: 0.8143\n",
            "Epoch 8/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8291 - val_loss: 0.8176\n",
            "Epoch 9/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8281 - val_loss: 0.8141\n",
            "Epoch 10/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8230 - val_loss: 0.8210\n",
            "Epoch 11/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8231 - val_loss: 0.8084\n",
            "Epoch 12/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8197 - val_loss: 0.8085\n",
            "Epoch 13/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8180 - val_loss: 0.8060\n",
            "Epoch 14/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8159 - val_loss: 0.8058\n",
            "Epoch 15/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8142 - val_loss: 0.8040\n",
            "Epoch 16/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8126 - val_loss: 0.8046\n",
            "Epoch 17/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8129 - val_loss: 0.8077\n",
            "Epoch 18/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8111 - val_loss: 0.8039\n",
            "Epoch 19/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8098 - val_loss: 0.8117\n",
            "Epoch 20/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8095 - val_loss: 0.8014\n",
            "Epoch 21/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8072 - val_loss: 0.8012\n",
            "Epoch 22/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8065 - val_loss: 0.8067\n",
            "Epoch 23/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8069 - val_loss: 0.8171\n",
            "Epoch 24/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8058 - val_loss: 0.8054\n",
            "Epoch 25/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8057 - val_loss: 0.8020\n",
            "Epoch 26/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8039 - val_loss: 0.8081\n",
            "Epoch 27/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8043 - val_loss: 0.8003\n",
            "Epoch 28/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8036 - val_loss: 0.8063\n",
            "Epoch 29/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8041 - val_loss: 0.8029\n",
            "Epoch 30/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8022 - val_loss: 0.8013\n",
            "Epoch 31/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8023 - val_loss: 0.8076\n",
            "Epoch 32/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8029 - val_loss: 0.8074\n",
            "Epoch 33/50\n",
            "1165581/1165581 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8003 - val_loss: 0.8085\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x7f2aeb8e6f98\u003e"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again I am running this multiple times\n",
        "emb_model.fit([long_more_train_set.features, long_more_train_set.cont_ids], \n",
        "              long_more_train_set.targets, \n",
        "              epochs\u003d50, batch_size\u003d4096, validation_split\u003d0.2,\n",
        "              callbacks\u003d[EarlyStopping(monitor\u003d\u0027val_loss\u0027, \n",
        "                                       min_delta\u003d0,\n",
        "                                       patience\u003d5)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "170000/182218 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003e...] - ETA: 0s"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.79416574978415233"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model.evaluate([more_test_set.features, more_test_set.cont_ids], more_test_set.targets, \n",
        "                   batch_size\u003d10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "preds \u003d emb_model.predict([more_test_set.features, more_test_set.cont_ids])\n",
        "results_df \u003d create_results_df(test_set.date_strs, test_set.station_ids,\n",
        "                               preds[:, 0], preds[:, 1])\n",
        "results_df.to_csv(results_dir + \u0027embedding_nn_more_aux_train_2008-2015_pred_2016.csv\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "source": [
        "## Data augmentation\n",
        "\n",
        "Let\u0027s pick a setup where overfitting is a problem: emb_train_2015_aux "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "with open(DATA_DIR + \u0027aux_15_16.pkl\u0027, \u0027rb\u0027) as f:\n",
        "    train_set, test_set \u003d pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(180849, 40)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0.25074708,   0.09660812,   0.1843026 ,   0.09279162,\n",
              "         0.03468666,   0.13954796,   0.22625588,   0.07106367,\n",
              "         0.30288959,   0.08776672,   0.02569887,   0.09980575,\n",
              "         0.23046067,   0.06643367,   0.20091382,   0.08406494,\n",
              "         0.19337422,   0.11743076,   0.05346011,   0.06231587,\n",
              "         0.02710444,   0.0817729 ,   0.31899199,   0.23367222,\n",
              "         0.30816635,   0.09623598,   0.91393036,   0.1034622 ,\n",
              "         0.13670425,   0.05991281,   0.13355759,   0.05574263,\n",
              "         0.23230664,   0.14413203,  12.44298172,   0.10215613,\n",
              "         0.02040521,   0.09879841,   0.15911838,   0.10272128], dtype\u003dfloat32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.std(axis\u003d0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.23806411,  0.09815978,  0.6862545 ,  0.17456083,  0.1688834 ,\n",
              "        0.22585876,  0.17900802,  0.21563105,  0.19999588,  0.01879581,\n",
              "        0.20672929,  0.44667143,  0.15995905,  0.14729995,  0.10025162,\n",
              "        0.09625338,  0.20209451,  0.26052597,  0.21735674,  0.11991174], dtype\u003dfloat32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.mean(axis\u003d0)[1::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0.25074708,   0.1843026 ,   0.03468666,   0.22625588,\n",
              "         0.30288959,   0.02569887,   0.23046067,   0.20091382,\n",
              "         0.19337422,   0.05346011,   0.02710444,   0.31899199,\n",
              "         0.30816635,   0.91393036,   0.13670425,   0.13355759,\n",
              "         0.23230664,  12.44298172,   0.02040521,   0.15911838], dtype\u003dfloat32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.std(axis\u003d0)[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "scales \u003d np.zeros(train_set.features.shape[1])\n",
        "scales[1::2] \u003d train_set.features.mean(axis\u003d0)[1::2]\n",
        "scales[::2] \u003d train_set.features.std(axis\u003d0)[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "features_aug \u003d train_set.features + np.random.normal(size\u003dtrain_set.features.shape) * scales * 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "targets_aug \u003d train_set.targets + np.random.normal(scale\u003d0.1, size\u003dtrain_set.targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 2.20000005, -3.70000005, -2.0999999 ,  1.60000002,  0.60000002], dtype\u003dfloat32),\n",
              " array([ 2.11051623, -3.64067068, -2.10724395,  1.64481148,  0.62672574]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.targets[:5], targets_aug[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(361698, 40)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.concatenate([train_set.features, features_aug], axis\u003d0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "emb_model \u003d build_emb_model(train_set.features.shape[1], 2, [100], 3, max_id, \n",
        "                            compile\u003dTrue, lr\u003d0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 180849 samples, validate on 182218 samples\n",
            "Epoch 1/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 3.2343 - val_loss: 2.0386\n",
            "Epoch 2/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.5920 - val_loss: 1.2551\n",
            "Epoch 3/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.1297 - val_loss: 1.0354\n",
            "Epoch 4/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0138 - val_loss: 0.9986\n",
            "Epoch 5/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9730 - val_loss: 0.9816\n",
            "Epoch 6/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9539 - val_loss: 0.9707\n",
            "Epoch 7/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9516 - val_loss: 0.9200\n",
            "Epoch 8/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9236 - val_loss: 0.9069\n",
            "Epoch 9/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9131 - val_loss: 0.9088\n",
            "Epoch 10/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.9202 - val_loss: 0.8905\n",
            "Epoch 11/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8831 - val_loss: 0.8939\n",
            "Epoch 12/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8870 - val_loss: 0.8651\n",
            "Epoch 13/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8858 - val_loss: 0.9388\n",
            "Epoch 14/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8664 - val_loss: 0.9250\n",
            "Epoch 15/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8639 - val_loss: 0.8529\n",
            "Epoch 16/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8575 - val_loss: 0.8634\n",
            "Epoch 17/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8542 - val_loss: 0.8478\n",
            "Epoch 18/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8571 - val_loss: 0.8445\n",
            "Epoch 19/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8558 - val_loss: 0.8832\n",
            "Epoch 20/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8462 - val_loss: 0.8447\n",
            "Epoch 21/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8489 - val_loss: 0.8766\n",
            "Epoch 22/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8635 - val_loss: 0.8424\n",
            "Epoch 23/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8373 - val_loss: 0.8437\n",
            "Epoch 24/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8529 - val_loss: 0.8776\n",
            "Epoch 25/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8384 - val_loss: 0.8514\n",
            "Epoch 26/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8314 - val_loss: 0.8553\n",
            "Epoch 27/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8375 - val_loss: 0.8580\n",
            "Epoch 28/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8350 - val_loss: 0.8668\n",
            "Epoch 29/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8404 - val_loss: 0.8421\n",
            "Epoch 30/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8461 - val_loss: 0.8423\n",
            "Epoch 31/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8248 - val_loss: 0.8341\n",
            "Epoch 32/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8283 - val_loss: 0.8523\n",
            "Epoch 33/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8198 - val_loss: 0.8482\n",
            "Epoch 34/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8310 - val_loss: 0.8331\n",
            "Epoch 35/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8222 - val_loss: 0.8319\n",
            "Epoch 36/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8189 - val_loss: 0.8382\n",
            "Epoch 37/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8121 - val_loss: 0.8333\n",
            "Epoch 38/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8218 - val_loss: 0.8762\n",
            "Epoch 39/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8200 - val_loss: 0.8326\n",
            "Epoch 40/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8174 - val_loss: 0.8369\n",
            "Epoch 41/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8083 - val_loss: 0.9549\n",
            "Epoch 42/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8314 - val_loss: 0.8978\n",
            "Epoch 43/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8168 - val_loss: 0.8370\n",
            "Epoch 44/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8087 - val_loss: 0.8263\n",
            "Epoch 45/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8095 - val_loss: 0.8355\n",
            "Epoch 46/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8147 - val_loss: 0.8359\n",
            "Epoch 47/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8046 - val_loss: 0.8279\n",
            "Epoch 48/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8052 - val_loss: 0.8314\n",
            "Epoch 49/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8076 - val_loss: 0.8436\n",
            "Epoch 50/50\n",
            "180849/180849 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8062 - val_loss: 0.8263\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x12b5c9630\u003e"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model.fit([train_set.features, train_set.cont_ids], train_set.targets, \n",
        "              epochs\u003d50, batch_size\u003d4096, \n",
        "              validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 361698 samples, validate on 182218 samples\n",
            "Epoch 1/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 2.1479 - val_loss: 1.1412\n",
            "Epoch 2/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 1.0383 - val_loss: 0.9549\n",
            "Epoch 3/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9582 - val_loss: 0.9531\n",
            "Epoch 4/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.9008 - val_loss: 0.8797\n",
            "Epoch 5/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8987 - val_loss: 0.8848\n",
            "Epoch 6/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8709 - val_loss: 0.8621\n",
            "Epoch 7/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8752 - val_loss: 0.8749\n",
            "Epoch 8/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8617 - val_loss: 0.8502\n",
            "Epoch 9/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8640 - val_loss: 0.8468\n",
            "Epoch 10/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8564 - val_loss: 0.8448\n",
            "Epoch 11/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8538 - val_loss: 0.8694\n",
            "Epoch 12/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8438 - val_loss: 0.9038\n",
            "Epoch 13/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8354 - val_loss: 0.8437\n",
            "Epoch 14/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8413 - val_loss: 0.8433\n",
            "Epoch 15/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8383 - val_loss: 0.8457\n",
            "Epoch 16/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8365 - val_loss: 0.8394\n",
            "Epoch 17/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8243 - val_loss: 0.8495\n",
            "Epoch 18/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8340 - val_loss: 0.8458\n",
            "Epoch 19/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8226 - val_loss: 0.8358\n",
            "Epoch 20/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8305 - val_loss: 0.8430\n",
            "Epoch 21/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8223 - val_loss: 0.8531\n",
            "Epoch 22/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8124 - val_loss: 0.8298\n",
            "Epoch 23/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8186 - val_loss: 0.8460\n",
            "Epoch 24/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8160 - val_loss: 0.8631\n",
            "Epoch 25/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8179 - val_loss: 0.8536\n",
            "Epoch 26/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8146 - val_loss: 0.8309\n",
            "Epoch 27/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8036 - val_loss: 0.8502\n",
            "Epoch 28/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8138 - val_loss: 0.8647\n",
            "Epoch 29/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8110 - val_loss: 0.8750\n",
            "Epoch 30/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8002 - val_loss: 0.8296\n",
            "Epoch 31/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8122 - val_loss: 0.8344\n",
            "Epoch 32/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8066 - val_loss: 0.8359\n",
            "Epoch 33/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8050 - val_loss: 0.8449\n",
            "Epoch 34/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8078 - val_loss: 0.9519\n",
            "Epoch 35/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.8057 - val_loss: 0.8442\n",
            "Epoch 36/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7934 - val_loss: 0.8372\n",
            "Epoch 37/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7956 - val_loss: 0.8692\n",
            "Epoch 38/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8037 - val_loss: 0.8927\n",
            "Epoch 39/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.8000 - val_loss: 0.8506\n",
            "Epoch 40/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.7956 - val_loss: 0.8389\n",
            "Epoch 41/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.7931 - val_loss: 0.8425\n",
            "Epoch 42/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7926 - val_loss: 0.8395\n",
            "Epoch 43/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7954 - val_loss: 0.9836\n",
            "Epoch 44/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7983 - val_loss: 0.8360\n",
            "Epoch 45/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7962 - val_loss: 0.8373\n",
            "Epoch 46/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7904 - val_loss: 0.8407\n",
            "Epoch 47/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7930 - val_loss: 0.8393\n",
            "Epoch 48/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 2s - loss: 0.7886 - val_loss: 0.8699\n",
            "Epoch 49/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7915 - val_loss: 0.8483\n",
            "Epoch 50/50\n",
            "361698/361698 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s - loss: 0.7899 - val_loss: 0.8451\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u003ckeras.callbacks.History at 0x1288b6a20\u003e"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model.fit([\n",
        "    np.concatenate([train_set.features, features_aug], axis\u003d0), \n",
        "    np.concatenate([train_set.cont_ids, train_set.cont_ids])\n",
        "                   ], np.concatenate([train_set.targets, targets_aug]), \n",
        "              epochs\u003d50, batch_size\u003d4096, \n",
        "              validation_data\u003d[[test_set.features, test_set.cont_ids], test_set.targets])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set contains 365 days\n",
            "test set contains 366 days\n"
          ]
        }
      ],
      "source": [
        "# Test current error\n",
        "train_dates \u003d [\u00272015-01-01\u0027, \u00272016-01-01\u0027]\n",
        "test_dates \u003d  [\u00272016-01-01\u0027, \u00272017-01-01\u0027]\n",
        "train_set, test_set \u003d get_train_test_sets(DATA_DIR, train_dates, test_dates,\n",
        "                                          add_current_error\u003dTrue, \n",
        "                                          current_error_len\u003d3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(195929, 11)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\u0027t2m_fc_mean\u0027,\n",
              " \u0027t2m_fc_std\u0027,\n",
              " \u0027curr_t2m_fc_mean\u0027,\n",
              " \u0027curr_t2m_fc_obs\u0027,\n",
              " \u0027curr_err\u0027,\n",
              " \u0027curr_t2m_fc_mean_m1\u0027,\n",
              " \u0027curr_t2m_fc_obs_m1\u0027,\n",
              " \u0027curr_err_m1\u0027,\n",
              " \u0027curr_t2m_fc_mean_m2\u0027,\n",
              " \u0027curr_t2m_fc_obs_m2\u0027,\n",
              " \u0027curr_err_m2\u0027]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}